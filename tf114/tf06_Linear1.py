# 가상환경 : tf114cpu

import tensorflow as tf

#1. 데이터
x = [1,2,3]
y = [1,2,3]

w = tf.Variable(111, dtype=tf.float32)      # 111 -> 0.1
b = tf.Variable(0, dtype=tf.float32)

#2. 모델 구성
# y = wx + b -> y = xw + b
hypothesis = x * w + b

#3-1. 컴파일
# model.compile(loss='mse', optimizer='sgd')
loss = tf.reduce_mean(tf.square(hypothesis - y))    # mse

# optimizer = tf.train.AdamOptimizer(learning_rate=0.1)   # 0.01 -> 0.1
optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)   # 0.01 -> 0.1
train = optimizer.minimize(loss)

#3-2. 훈련
sess = tf.compat.v1.Session()
sess.run(tf.global_variables_initializer())

# model.fit()
epochs = 1001
for step in range(epochs):
    sess.run(train)
    if step % 20 == 0:
        print(step, sess.run(loss), sess.run(w), sess.run(b))
sess.close()

# 초기w 값이 크다. -> w, lr, epochs 수정

'''
0 44682.156 100.73333 -4.4
1 35366.906 91.60088 -8.301333
2 28003.469 83.47685 -11.759342
3 22182.836 76.24939 -14.82323
4 17581.705 69.81904 -17.536741
5 13944.531 64.0974 -19.938768
6 11069.3125 59.005856 -22.063889
7 8796.384 54.474533 -23.942844
8 6999.531 50.44129 -25.602968
9 5578.9897 46.85089 -27.068562
10 4455.9062 43.654217 -28.361225
11 3567.948 40.807606 -29.50017
12 2865.8445 38.272236 -30.50247
13 2310.6501 36.01359 -31.38331
14 1871.5806 34.000988 -32.15619
15 1524.3036 32.20714 -32.833103
16 1249.5834 30.6078 -33.42473
17 1032.2177 29.181395 -33.940544
18 860.1879 27.908752 -34.38899
19 723.99506 26.77283 -34.777557
20 616.13007 25.758467 -35.11292
21 530.658 24.852194 -35.401
22 462.88742 24.042028 -35.647068
23 409.10986 23.317322 -35.85581
24 366.39404 22.668604 -36.031384
25 332.4228 22.087456 -36.1775
26 305.36484 21.566393 -36.29745
27 283.77234 21.09876 -36.394157
28 266.5011 20.678642 -36.470226
29 252.64644 20.300777 -36.52797
30 241.49347 19.960491 -36.569443
31 232.47694 19.653624 -36.596474
32 225.15019 19.376478 -36.610687
33 219.16002 19.125769 -36.613533
34 214.2273 18.898571 -36.606293
35 210.13135 18.69229 -36.59011
36 206.69788 18.504614 -36.566
37 203.78894 18.33349 -36.534866
38 201.29553 18.177094 -36.49751
39 199.13152 18.033798 -36.454643
40 197.22882 17.902163 -36.406902
41 195.53357 17.780903 -36.35485
42 194.00325 17.668879 -36.29899
43 192.60417 17.565077 -36.239765
44 191.30983 17.468594 -36.177574
45 190.09908 17.378628 -36.112766
46 188.95537 17.294466 -36.045654
47 187.86548 17.215475 -35.97652
48 186.81914 17.141092 -35.90561
49 185.80797 17.070814 -35.83314
50 184.82562 17.004198 -35.75931
51 183.86682 16.940845 -35.68429
52 182.92755 16.880405 -35.60824
53 182.0046 16.822563 -35.53129
54 181.09538 16.767042 -35.453564
55 180.19798 16.713594 -35.375175
56 179.31065 16.661999 -35.296215
57 178.4322 16.61206 -35.21677
58 177.56163 16.563606 -35.136917
59 176.6981 16.51648 -35.056725
60 175.841 16.470543 -34.97625
61 174.98985 16.425676 -34.895546
62 174.14417 16.38177 -34.814663
63 173.30367 16.338724 -34.73364
64 172.4681 16.296455 -34.652515
65 171.63722 16.254887 -34.571323
66 170.81093 16.213951 -34.490093
67 169.98903 16.173586 -34.408848
68 169.1714 16.133738 -34.327614
69 168.35799 16.09436 -34.24641
70 167.54869 16.05541 -34.165257
71 166.74347 16.01685 -34.084167
72 165.94225 15.978643 -34.00316
73 165.14497 15.940763 -33.92224
74 164.35161 15.903182 -33.841427
75 163.56215 15.865875 -33.760727
76 162.77654 15.828823 -33.68015
77 161.9947 15.792006 -33.5997
78 161.21669 15.755406 -33.519386
79 160.44244 15.71901 -33.439217
80 159.67189 15.682805 -33.35919
81 158.90503 15.646777 -33.27932
82 158.14194 15.610917 -33.199604
83 157.38249 15.575215 -33.12005
84 156.62666 15.539664 -33.040657
85 155.87451 15.504255 -32.96143
86 155.12595 15.468982 -32.88237
87 154.38103 15.433838 -32.803482
88 153.63966 15.398819 -32.724766
89 152.90186 15.36392 -32.646225
90 152.16762 15.329137 -32.567856
91 151.4369 15.294465 -32.489666
92 150.70967 15.259902 -32.41165
93 149.98595 15.225444 -32.333817
94 149.2657 15.191089 -32.256157
95 148.54893 15.156834 -32.178677
96 147.83556 15.122676 -32.101376
97 147.12563 15.088614 -32.024254
98 146.41911 15.054647 -31.947313
99 145.71599 15.020773 -31.870552
100 145.01625 14.98699 -31.793972
'''
